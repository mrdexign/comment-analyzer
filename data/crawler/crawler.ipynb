{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dk_code_extractor(dk_link):\n",
    "    pattern = r\"(dkp-)?(?P<code>\\d+)\"\n",
    "    match = re.search(pattern, dk_link)\n",
    "    return match.group(\"code\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Get & saving the products list</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_products_of_category(category):\n",
    "    total = []\n",
    "    url = f\"https://api.digikala.com/v1/categories/{category}/search/\"\n",
    "\n",
    "    # Initial pager\n",
    "    cur_page = 1\n",
    "    total_pages = 1\n",
    "    max_page_limit = 100\n",
    "    max_retry_on_error = 5\n",
    "\n",
    "    sys.stdout.write(f\"\\n{category} pages:\\n\")\n",
    "\n",
    "    def get_page(page=1):\n",
    "        nonlocal total_pages, total, max_retry_on_error\n",
    "\n",
    "        while max_retry_on_error > 0:\n",
    "            try:\n",
    "                response = requests.get(url, params={\"page\": page})\n",
    "                response = response.json()\n",
    "                if not response:\n",
    "                    raise ValueError(\"Empty response\")\n",
    "                break\n",
    "            except Exception:\n",
    "                max_retry_on_error -= 1\n",
    "                if max_retry_on_error >0:\n",
    "                    print(f\"ðŸ”´Error occurred, ({max_retry_on_error}) retying...\")\n",
    "                    time.sleep(5)\n",
    "\n",
    "        products = response[\"data\"][\"products\"]\n",
    "        total_pages = response[\"data\"][\"pager\"][\"total_pages\"]\n",
    "\n",
    "        sys.stdout.write(f\"âœ…{format(page, '02d')} \")\n",
    "        if page % 20 == 0:\n",
    "            sys.stdout.write(\"\\n\")\n",
    "\n",
    "        for product in products:\n",
    "            total.append({\"id\": product[\"id\"]})\n",
    "\n",
    "    while cur_page <= total_pages and cur_page <= max_page_limit:\n",
    "        get_page(cur_page)\n",
    "        cur_page += 1\n",
    "\n",
    "    return {\"products\": total, \"category\": category}\n",
    "\n",
    "\n",
    "def save_products(category):\n",
    "    result = get_products_of_category(category)\n",
    "    products = result[\"products\"]\n",
    "\n",
    "    print(f\"\\n{len(products)} products of {category} category retrieved!\")\n",
    "\n",
    "    file_path = f\"products/{category} ({len(products)}).csv\"\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "    with open(file_path, \"w\", encoding=\"UTF8\", newline=\"\") as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=[\"id\"])\n",
    "        writer.writerows(products)\n",
    "\n",
    "\n",
    "# categories = [\"electronic-devices\", \"laptop\", \"mobile-phone\"]\n",
    "# for category in categories:\n",
    "#     save_products(category)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Reading the saved products</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the product IDs\n",
    "def get_all_products():\n",
    "    ids = []\n",
    "    path = './products/'\n",
    "    for filename in os.listdir(path):\n",
    "        file_path = os.path.join(path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, \"r\") as file:\n",
    "                ids.extend(map(lambda line: line.rstrip(), file))\n",
    "    return ids\n",
    "    \n",
    "# get_all_products()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Get & saving the comments</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(dk_link):\n",
    "    total = []\n",
    "    code = dk_code_extractor(dk_link)\n",
    "    url = f\"https://api.digikala.com/v1/product/{code}/comments/\"\n",
    "\n",
    "    # Initial pager\n",
    "    cur_page = 1\n",
    "    total_pages = 1\n",
    "    max_page_limit = 5\n",
    "    max_retry_on_error = 3\n",
    "\n",
    "    def get_page(page=1):\n",
    "        nonlocal total_pages, total, max_page_limit, max_retry_on_error\n",
    "        while max_retry_on_error > 0:\n",
    "            try:\n",
    "                response = requests.get(url, params={\"page\": page})\n",
    "                response = response.json()\n",
    "                if \"data\" not in response:\n",
    "                    raise ValueError(\"Empty response\")\n",
    "                if \"comments\" not in response['data']:\n",
    "                    raise ValueError(\"Empty response\")\n",
    "                break\n",
    "            except Exception:\n",
    "                max_retry_on_error -= 1\n",
    "                if max_retry_on_error > 0:\n",
    "                    print(f\"ðŸ”´Error occurred {code}, ({max_retry_on_error}) retying...\")\n",
    "                    time.sleep(5)  \n",
    "                else:\n",
    "                    return {\"comments\": [], \"code\": code}\n",
    "\n",
    "        sys.stdout.write(f\"âœ…{format(page, '02d')} \")\n",
    "        if page % 20 == 0:\n",
    "            sys.stdout.write(\"\\n\")\n",
    "\n",
    "        text_comments = response[\"data\"][\"comments\"]\n",
    "        # media_comments = response[\"data\"][\"media_comments\"]\n",
    "        total_pages = response[\"data\"][\"pager\"][\"total_pages\"]\n",
    "\n",
    "        comments = text_comments\n",
    "        # comments += media_comments\n",
    "        for comment in comments:\n",
    "            rate = comment[\"rate\"]\n",
    "            text = comment[\"body\"]\n",
    "            if text is not None:\n",
    "                text = text.replace(\"\\n\",\" \").replace(\"\\t\",\" \")\n",
    "                total.append({\"rate\": rate, \"text\": text})\n",
    "\n",
    "    while cur_page <= total_pages and cur_page <= max_page_limit:\n",
    "        get_page(cur_page)\n",
    "        cur_page += 1\n",
    "\n",
    "    return {\"comments\": total, \"code\": code}\n",
    "\n",
    "\n",
    "def save_comments(dk_link):\n",
    "    print(f\"\\nGetting the comments of `dkp-{dk_link}` ...\")\n",
    "    result = get_comments(dk_link)\n",
    "    code = result[\"code\"]\n",
    "    comments = result[\"comments\"]\n",
    "\n",
    "    print(f\"\\n{len(comments)} comments of dkp-{code} retrieved!\")\n",
    "\n",
    "    file_path = f\"comments/{code} ({len(comments)}).csv\"\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "    with open(file_path, \"w\", encoding=\"UTF8\", newline=\"\") as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=[\"rate\", \"text\"])\n",
    "        writer.writerows(comments)\n",
    "\n",
    "\n",
    "# comments = get_all_products()\n",
    "# print(f\"âœ… {len(comments)} Product IDs fetched.\")\n",
    "# for id in comments:\n",
    "#     save_comments(id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ…144715 comments saved.\n"
     ]
    }
   ],
   "source": [
    "# Reading the saved comments\n",
    "def aggregate_saved_comments():\n",
    "    comments = []\n",
    "    path = \"./comments/\"\n",
    "    for filename in os.listdir(path):\n",
    "        file_path = os.path.join(path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, encoding=\"utf8\", mode=\"r\") as file:\n",
    "                reader = csv.reader(file)\n",
    "                comments.extend(reader)\n",
    "    return comments\n",
    "\n",
    "\n",
    "def save_comments_dataset():\n",
    "    saved_comments = aggregate_saved_comments()\n",
    "\n",
    "    # Remove un-labeled comments\n",
    "    saved_comments = list(filter(lambda c: c[0] != \"0\", saved_comments))\n",
    "\n",
    "    with open(\"../comments.csv\", \"w\", encoding=\"UTF8\", newline=\"\") as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        for comment in saved_comments:\n",
    "            writer.writerow([comment[0], comment[1]])\n",
    "    print(f\"âœ…{len(saved_comments)} comments saved.\")\n",
    "\n",
    "\n",
    "save_comments_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
